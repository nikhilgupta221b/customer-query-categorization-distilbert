{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12686245,"sourceType":"datasetVersion","datasetId":8017111}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:25:57.718415Z","iopub.execute_input":"2025-08-06T04:25:57.718640Z","iopub.status.idle":"2025-08-06T04:27:22.621719Z","shell.execute_reply.started":"2025-08-06T04:25:57.718617Z","shell.execute_reply":"2025-08-06T04:27:22.620964Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport pickle\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    Trainer, \n    TrainingArguments,\n    pipeline,\n    DataCollatorWithPadding,\n    EvalPrediction\n)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:27:22.622961Z","iopub.execute_input":"2025-08-06T04:27:22.623267Z","iopub.status.idle":"2025-08-06T04:27:52.880381Z","shell.execute_reply.started":"2025-08-06T04:27:22.623234Z","shell.execute_reply":"2025-08-06T04:27:52.879638Z"}},"outputs":[{"name":"stderr","text":"2025-08-06 04:27:37.607773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754454457.828468      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754454457.892600      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Model saving configuration\nMODEL_SAVE_DIR = \"./saved_ticket_classifier_downsampled\"\nTOKENIZER_SAVE_DIR = os.path.join(MODEL_SAVE_DIR, \"tokenizer\")\nMODEL_WEIGHTS_DIR = os.path.join(MODEL_SAVE_DIR, \"model\")\nMETADATA_FILE = os.path.join(MODEL_SAVE_DIR, \"metadata.json\")\nLABEL_ENCODER_FILE = os.path.join(MODEL_SAVE_DIR, \"label_encoder.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:27:52.884610Z","iopub.execute_input":"2025-08-06T04:27:52.884917Z","iopub.status.idle":"2025-08-06T04:27:52.889849Z","shell.execute_reply.started":"2025-08-06T04:27:52.884887Z","shell.execute_reply":"2025-08-06T04:27:52.888976Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def create_save_directories():\n    \"\"\"Create directories for saving model components\"\"\"\n    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n    os.makedirs(TOKENIZER_SAVE_DIR, exist_ok=True)\n    os.makedirs(MODEL_WEIGHTS_DIR, exist_ok=True)\n    print(f\"Created save directories: {MODEL_SAVE_DIR}\")\n\ndef save_model_components(model, tokenizer, label_encoder, training_config, results):\n    \"\"\"Save all model components needed for inference\"\"\"\n    create_save_directories()\n    \n    print(\"Saving model components...\")\n    \n    # Save the trained model\n    model.save_pretrained(MODEL_WEIGHTS_DIR)\n    print(f\"✓ Model saved to: {MODEL_WEIGHTS_DIR}\")\n    \n    # Save the tokenizer\n    tokenizer.save_pretrained(TOKENIZER_SAVE_DIR)\n    print(f\"✓ Tokenizer saved to: {TOKENIZER_SAVE_DIR}\")\n    \n    # Save label encoder\n    with open(LABEL_ENCODER_FILE, 'wb') as f:\n        pickle.dump(label_encoder, f)\n    print(f\"✓ Label encoder saved to: {LABEL_ENCODER_FILE}\")\n    \n    # Save metadata and configuration\n    metadata = {\n        \"model_name\": \"distilbert-base-uncased\",\n        \"num_labels\": len(label_encoder.classes_),\n        \"label_classes\": label_encoder.classes_.tolist(),\n        \"max_length\": 512,\n        \"training_config\": training_config,\n        \"results\": results,\n        \"save_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"preprocessing_params\": {\n            \"method\": \"downsampling_for_balance\",\n            \"tokenizer_model\": \"distilbert-base-uncased\"\n        }\n    }\n    \n    with open(METADATA_FILE, 'w') as f:\n        json.dump(metadata, f, indent=2, default=str)\n    print(f\"✓ Metadata saved to: {METADATA_FILE}\")\n    \n    print(f\"\\n✅ All model components saved successfully to: {MODEL_SAVE_DIR}\")\n    return MODEL_SAVE_DIR","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:27:52.890724Z","iopub.execute_input":"2025-08-06T04:27:52.891021Z","iopub.status.idle":"2025-08-06T04:27:52.906928Z","shell.execute_reply.started":"2025-08-06T04:27:52.890994Z","shell.execute_reply":"2025-08-06T04:27:52.906127Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model_for_inference(model_dir=MODEL_SAVE_DIR):\n    \"\"\"\n    Load all model components for inference\n    \"\"\"\n    print(f\"Loading model components from: {model_dir}\")\n    \n    # Load metadata\n    with open(os.path.join(model_dir, \"metadata.json\"), 'r') as f:\n        metadata = json.load(f)\n    \n    # Load tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(os.path.join(model_dir, \"tokenizer\"))\n    \n    # Load model\n    model = AutoModelForSequenceClassification.from_pretrained(os.path.join(model_dir, \"model\"))\n    \n    # Load label encoder\n    with open(os.path.join(model_dir, \"label_encoder.pkl\"), 'rb') as f:\n        label_encoder = pickle.load(f)\n    \n    print(\"✅ Model components loaded successfully!\")\n    print(f\"Model: {metadata['model_name']}\")\n    print(f\"Number of classes: {metadata['num_labels']}\")\n    print(f\"Classes: {metadata['label_classes']}\")\n    \n    return model, tokenizer, label_encoder, metadata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:27:52.907885Z","iopub.execute_input":"2025-08-06T04:27:52.908212Z","iopub.status.idle":"2025-08-06T04:27:52.928956Z","shell.execute_reply.started":"2025-08-06T04:27:52.908182Z","shell.execute_reply":"2025-08-06T04:27:52.928147Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def predict_ticket_category(text, model, tokenizer, label_encoder, device='cpu', max_length=512):\n    \"\"\"\n    Predict the category of a single ticket text\n    \"\"\"\n    model.eval()\n    model.to(device)\n    \n    # Tokenize input\n    encoding = tokenizer(\n        str(text),\n        truncation=True,\n        padding='max_length',\n        max_length=max_length,\n        return_tensors='pt'\n    )\n    \n    # Move to device\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    # Make prediction\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n        predicted_class = torch.argmax(predictions, dim=-1).cpu().numpy()[0]\n        confidence = torch.max(predictions).cpu().numpy()\n    \n    # Convert back to original label\n    predicted_label = label_encoder.inverse_transform([predicted_class])[0]\n    \n    return {\n        'predicted_class': predicted_label,\n        'confidence': float(confidence),\n        'class_probabilities': {\n            label_encoder.classes_[i]: float(predictions[0][i].cpu().numpy()) \n            for i in range(len(label_encoder.classes_))\n        }\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:27:52.929777Z","iopub.execute_input":"2025-08-06T04:27:52.930061Z","iopub.status.idle":"2025-08-06T04:27:52.949932Z","shell.execute_reply.started":"2025-08-06T04:27:52.930037Z","shell.execute_reply":"2025-08-06T04:27:52.949182Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def downsample_dataframe(df, target_column='queue'):\n    \"\"\"\n    Downsample the majority classes to match the size of the smallest class.\n    \"\"\"\n    class_counts = df[target_column].value_counts()\n    min_class_size = class_counts.min()\n    \n    print(f\"Original class distribution:\\n{class_counts}\")\n    print(f\"\\nSmallest class size: {min_class_size}. Downsampling all classes to this size.\")\n    \n    downsampled_df = pd.DataFrame()\n    for class_name in class_counts.index:\n        class_subset = df[df[target_column] == class_name]\n        downsampled_subset = class_subset.sample(min_class_size, random_state=42)\n        downsampled_df = pd.concat([downsampled_df, downsampled_subset], ignore_index=True)\n    \n    # Shuffle the final dataset to mix the classes\n    downsampled_df = downsampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    print(f\"\\nNew (downsampled) class distribution:\\n{downsampled_df[target_column].value_counts()}\")\n    return downsampled_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:27:52.952242Z","iopub.execute_input":"2025-08-06T04:27:52.952481Z","iopub.status.idle":"2025-08-06T04:27:52.968641Z","shell.execute_reply.started":"2025-08-06T04:27:52.952455Z","shell.execute_reply":"2025-08-06T04:27:52.967848Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load and Prepare Dataset\nprint(\"Loading dataset...\")\ndf = pd.read_csv(\"/kaggle/input/processedtickets2/processed_tickets.csv\")\n\n# Basic data cleaning\ndf = df.dropna(subset=['full_text', 'queue'])\ndf['full_text'] = df['full_text'].astype(str)\nprint(f\"Original dataset shape: {df.shape}\")\nprint(f\"Number of unique queues: {df['queue'].nunique()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:29:32.676974Z","iopub.execute_input":"2025-08-06T04:29:32.677526Z","iopub.status.idle":"2025-08-06T04:29:32.971541Z","shell.execute_reply.started":"2025-08-06T04:29:32.677501Z","shell.execute_reply":"2025-08-06T04:29:32.970701Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\nOriginal dataset shape: (11923, 7)\nNumber of unique queues: 5\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# --- Downsample the data to create a balanced dataset ---\ndownsampled_df = downsample_dataframe(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:29:35.232856Z","iopub.execute_input":"2025-08-06T04:29:35.233618Z","iopub.status.idle":"2025-08-06T04:29:35.270553Z","shell.execute_reply.started":"2025-08-06T04:29:35.233588Z","shell.execute_reply":"2025-08-06T04:29:35.269654Z"}},"outputs":[{"name":"stdout","text":"Original class distribution:\nqueue\nTechnical Support    5245\nProduct Support      2814\nCustomer Service     2027\nBilling Support      1302\nSales & HR            535\nName: count, dtype: int64\n\nSmallest class size: 535. Downsampling all classes to this size.\n\nNew (downsampled) class distribution:\nqueue\nProduct Support      535\nSales & HR           535\nTechnical Support    535\nBilling Support      535\nCustomer Service     535\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Encode target labels\nlabel_encoder = LabelEncoder()\ndownsampled_df['label'] = label_encoder.fit_transform(downsampled_df['queue'])\nnum_labels = len(label_encoder.classes_)\nprint(f\"\\nNumber of classes: {num_labels}\")\nprint(f\"Classes: {list(label_encoder.classes_)}\")\n\n# Select required columns\ndf_final = downsampled_df[['full_text', 'label']].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:29:41.392766Z","iopub.execute_input":"2025-08-06T04:29:41.393521Z","iopub.status.idle":"2025-08-06T04:29:41.400740Z","shell.execute_reply.started":"2025-08-06T04:29:41.393486Z","shell.execute_reply":"2025-08-06T04:29:41.399863Z"}},"outputs":[{"name":"stdout","text":"\nNumber of classes: 5\nClasses: ['Billing Support', 'Customer Service', 'Product Support', 'Sales & HR', 'Technical Support']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Split into train and validation sets\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df_final['full_text'], \n    df_final['label'], \n    test_size=0.2, \n    stratify=df_final['label'], \n    random_state=42\n)\nprint(f\"\\nDataset split:\")\nprint(f\"Training samples: {len(train_texts)}\")\nprint(f\"Validation samples: {len(val_texts)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:29:42.556632Z","iopub.execute_input":"2025-08-06T04:29:42.557156Z","iopub.status.idle":"2025-08-06T04:29:42.566524Z","shell.execute_reply.started":"2025-08-06T04:29:42.557132Z","shell.execute_reply":"2025-08-06T04:29:42.565853Z"}},"outputs":[{"name":"stdout","text":"\nDataset split:\nTraining samples: 2140\nValidation samples: 535\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Custom Dataset Class\nclass TicketDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=512):\n        self.texts = texts.reset_index(drop=True) if hasattr(texts, 'reset_index') else texts\n        self.labels = labels.reset_index(drop=True) if hasattr(labels, 'reset_index') else labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts.iloc[idx] if hasattr(self.texts, 'iloc') else self.texts[idx])\n        label = int(self.labels.iloc[idx] if hasattr(self.labels, 'iloc') else self.labels[idx])\n        \n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:29:43.406760Z","iopub.execute_input":"2025-08-06T04:29:43.407084Z","iopub.status.idle":"2025-08-06T04:29:43.413332Z","shell.execute_reply.started":"2025-08-06T04:29:43.407063Z","shell.execute_reply":"2025-08-06T04:29:43.412551Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def compute_metrics(eval_pred: EvalPrediction):\n    \"\"\"Compute accuracy metrics for evaluation\"\"\"\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    accuracy = accuracy_score(labels, predictions)\n    return {\n        'accuracy': accuracy,\n        'eval_samples': len(labels)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:29:44.495009Z","iopub.execute_input":"2025-08-06T04:29:44.495783Z","iopub.status.idle":"2025-08-06T04:29:44.500742Z","shell.execute_reply.started":"2025-08-06T04:29:44.495748Z","shell.execute_reply":"2025-08-06T04:29:44.499938Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Training and Evaluation Function\ndef train_distilbert_with_downsampling(train_texts, val_texts, train_labels, val_labels, num_labels):\n    print(f\"\\n--- Training DistilBERT with Downsampled Text ---\")\n    \n    model_name = \"distilbert-base-uncased\"\n    \n    # Load tokenizer and model\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name, \n        num_labels=num_labels\n    )\n    \n    # Create datasets\n    train_dataset = TicketDataset(train_texts, train_labels, tokenizer)\n    val_dataset = TicketDataset(val_texts, val_labels, tokenizer)\n    \n    print(f\"Created datasets - Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    \n    print(f\"Using device: {device}\")\n    \n    # Training arguments\n    training_args = TrainingArguments(\n        output_dir=\"./results/distilbert_downsampled\",\n        per_device_train_batch_size=64,\n        per_device_eval_batch_size=64,\n        num_train_epochs=30,\n        eval_strategy=\"epoch\",\n        logging_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_accuracy\",\n        greater_is_better=True,\n        report_to=\"none\",\n        dataloader_num_workers=0,\n        remove_unused_columns=False,\n        fp16=torch.cuda.is_available(),\n        logging_steps=50,\n        eval_steps=None,\n    )\n    \n    # Initialize trainer\n    # NOTE: Using standard Trainer as dataset is now balanced via downsampling.\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        tokenizer=tokenizer,\n        data_collator=DataCollatorWithPadding(tokenizer),\n        compute_metrics=compute_metrics\n    )\n    \n    # Train model\n    print(\"Starting training...\")\n    start_train = time.time()\n    trainer.train()\n    end_train = time.time()\n    training_time = end_train - start_train\n    \n    print(f\"Training completed in {training_time:.2f} seconds\")\n    \n    # Evaluate on validation set\n    print(\"Evaluating on validation set...\")\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_TRAINING)\n    \n    model.eval()\n    all_preds, all_labels = [], []\n    inference_times = []\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            start_inf = time.time()\n            \n            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n            labels = batch['labels']\n            outputs = model(**inputs)\n            \n            end_inf = time.time()\n            inference_times.append(end_inf - start_inf)\n            \n            all_preds.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n            all_labels.extend(labels.numpy())\n    \n    # Calculate metrics\n    accuracy = accuracy_score(all_labels, all_preds)\n    avg_inference_time = np.mean(inference_times)\n    \n    print(f\"\\nResults:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Average inference time per batch: {avg_inference_time:.4f} seconds\")\n    \n    # Detailed classification report\n    print(f\"\\nDetailed Classification Report:\")\n    target_names = [f\"Class_{i}\" for i in range(num_labels)]\n    print(classification_report(all_labels, all_preds, target_names=target_names))\n    \n    # Prepare training configuration for saving\n    training_config = {\n        \"model_name\": model_name,\n        \"num_train_epochs\": training_args.num_train_epochs,\n        \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n        \"per_device_eval_batch_size\": training_args.per_device_eval_batch_size,\n        \"learning_rate\": training_args.learning_rate,\n        \"fp16\": training_args.fp16\n    }\n    \n    results = {\n        'model': 'DistilBERT + Downsampling',\n        'training_time': training_time,\n        'inference_time': avg_inference_time,\n        'accuracy': accuracy,\n    }\n    \n    # Save all model components\n    save_path = save_model_components(model, tokenizer, label_encoder, training_config, results)\n    \n    # Add save path to results\n    results['save_path'] = save_path\n    \n    return results, model, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:29:58.209160Z","iopub.execute_input":"2025-08-06T04:29:58.209751Z","iopub.status.idle":"2025-08-06T04:29:58.220383Z","shell.execute_reply.started":"2025-08-06T04:29:58.209727Z","shell.execute_reply":"2025-08-06T04:29:58.219627Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Run the training\nprint(\"=\"*50)\nprint(\"STARTING TRAINING AND SAVING PROCESS\")\nprint(\"=\"*50)\n\nresults, trained_model, trained_tokenizer = train_distilbert_with_downsampling(\n    train_texts, val_texts, train_labels, val_labels, num_labels\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T04:30:07.373720Z","iopub.execute_input":"2025-08-06T04:30:07.374085Z","iopub.status.idle":"2025-08-06T04:56:13.312419Z","shell.execute_reply.started":"2025-08-06T04:30:07.374063Z","shell.execute_reply":"2025-08-06T04:56:13.311243Z"}},"outputs":[{"name":"stdout","text":"==================================================\nSTARTING TRAINING AND SAVING PROCESS\n==================================================\n\n--- Training DistilBERT with Downsampled Text ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"474fc89ff035499ea8b6c69a5f697a71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac8e679aa29641a6bbfa948556eec595"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a05dcf03c6b44872972268a83eb03d40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c09a424e56f4744b0a8bda24e58816d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3482cc6e95814dc594fb83334aabcdde"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Created datasets - Train: 2140, Val: 535\nUsing device: cuda\nStarting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='919' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 919/1020 25:52 < 02:50, 0.59 it/s, Epoch 27/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Samples</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.526100</td>\n      <td>1.385713</td>\n      <td>535</td>\n      <td>0.379439</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.307200</td>\n      <td>1.290287</td>\n      <td>535</td>\n      <td>0.452336</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.189800</td>\n      <td>1.269825</td>\n      <td>535</td>\n      <td>0.428037</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.056900</td>\n      <td>1.260724</td>\n      <td>535</td>\n      <td>0.467290</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.887900</td>\n      <td>1.313666</td>\n      <td>535</td>\n      <td>0.489720</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.719900</td>\n      <td>1.326769</td>\n      <td>535</td>\n      <td>0.487850</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.551600</td>\n      <td>1.376821</td>\n      <td>535</td>\n      <td>0.517757</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.378600</td>\n      <td>1.468429</td>\n      <td>535</td>\n      <td>0.493458</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.265400</td>\n      <td>1.632356</td>\n      <td>535</td>\n      <td>0.495327</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.184400</td>\n      <td>1.751629</td>\n      <td>535</td>\n      <td>0.512150</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.116100</td>\n      <td>1.953524</td>\n      <td>535</td>\n      <td>0.495327</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.086800</td>\n      <td>2.128806</td>\n      <td>535</td>\n      <td>0.502804</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.062600</td>\n      <td>2.205295</td>\n      <td>535</td>\n      <td>0.500935</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.059200</td>\n      <td>2.283444</td>\n      <td>535</td>\n      <td>0.508411</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.032600</td>\n      <td>2.439843</td>\n      <td>535</td>\n      <td>0.499065</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.029100</td>\n      <td>2.487655</td>\n      <td>535</td>\n      <td>0.521495</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.019500</td>\n      <td>2.692035</td>\n      <td>535</td>\n      <td>0.499065</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.017000</td>\n      <td>2.661950</td>\n      <td>535</td>\n      <td>0.504673</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.015200</td>\n      <td>2.821312</td>\n      <td>535</td>\n      <td>0.504673</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.013400</td>\n      <td>2.840060</td>\n      <td>535</td>\n      <td>0.506542</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.011500</td>\n      <td>2.879504</td>\n      <td>535</td>\n      <td>0.506542</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.008200</td>\n      <td>2.943433</td>\n      <td>535</td>\n      <td>0.514019</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.003700</td>\n      <td>2.983697</td>\n      <td>535</td>\n      <td>0.500935</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.006900</td>\n      <td>3.025883</td>\n      <td>535</td>\n      <td>0.517757</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.004500</td>\n      <td>3.034084</td>\n      <td>535</td>\n      <td>0.519626</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.003000</td>\n      <td>3.036623</td>\n      <td>535</td>\n      <td>0.506542</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.002400</td>\n      <td>3.023262</td>\n      <td>535</td>\n      <td>0.506542</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2164503745.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m results, trained_model, trained_tokenizer = train_distilbert_with_downsampling(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n","\u001b[0;32m/tmp/ipykernel_36/3250980562.py\u001b[0m in \u001b[0;36mtrain_distilbert_with_downsampling\u001b[0;34m(train_texts, val_texts, train_labels, val_labels, num_labels)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mstart_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mend_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2655\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2656\u001b[0;31m             self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2657\u001b[0m                 \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3197\u001b[0m         \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_strategy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSaveStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSaveStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_global_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3910\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3911\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   4013\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4014\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4015\u001b[0;31m             self.model.save_pretrained(\n\u001b[0m\u001b[1;32m   4016\u001b[0m                 \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_serialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_safetensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4017\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   3715\u001b[0m                 \u001b[0;31m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3716\u001b[0m                 \u001b[0;31m# joyfulness), but for now this enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3717\u001b[0;31m                 \u001b[0msafe_save_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3718\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3719\u001b[0m                 \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mserialize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSafetensorError\u001b[0m: Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })"],"ename":"SafetensorError","evalue":"Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"# Display results\nprint(f\"\\n{'='*50}\")\nprint(\"FINAL RESULTS SUMMARY\")\nprint(f\"{'='*50}\")\nprint(f\"Model: {results['model']}\")\nprint(f\"Training Time: {results['training_time']:.2f} seconds\")\nprint(f\"Average Inference Time: {results['inference_time']:.4f} seconds per batch\")\nprint(f\"Final Accuracy: {results['accuracy']:.4f}\")\nprint(f\"Model saved to: {results['save_path']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T05:06:22.274704Z","iopub.execute_input":"2025-08-06T05:06:22.274970Z","iopub.status.idle":"2025-08-06T05:06:22.348184Z","shell.execute_reply.started":"2025-08-06T05:06:22.274949Z","shell.execute_reply":"2025-08-06T05:06:22.347285Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nFINAL RESULTS SUMMARY\n==================================================\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3913574043.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FINAL RESULTS SUMMARY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'='*50}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model: {results['model']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training Time: {results['training_time']:.2f} seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average Inference Time: {results['inference_time']:.4f} seconds per batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"],"ename":"NameError","evalue":"name 'results' is not defined","output_type":"error"}],"execution_count":1}]}